---
title: "混合ガウスモデル"
weight: 1
# bookFlatSection: false
# bookShowToC: true
bookToc: false
---

# 混合ガウスモデル

先程のk-means法では、データを必ずどれか一つのクラスターに割り当てていたが、複数のクラスターに割り当てると言うことはできないだろうか？

ここで、教師あり学習でも利用した、確率を使った表現を利用することを考えてみる。

k-means法では入力データがどのクラスタに属するかを示すものとして行列Rを用いていた。

ここでは、この行列Rを、以下のように行列Γとして設定する。なお、入力データの個数をN個とする。

{{< katex  >}}
\tag{1}  {\bf \Gamma}  =  
                \left[
                    \begin{array}{cc}
                    {\bf \gamma}_{0} \\
                    {\bf \gamma}_{1} \\
                    \vdots \\
                    {\bf \gamma}_{N-1} \\
                    \end{array}
                \right]
{{< /katex >}}

ここでクラスタ数をKとした時、

{{< katex  >}}
\tag{2}  {\bf \gamma}_{i}  =  
                \left[
                    \begin{array}{cc}
                    \gamma_{i0}  & \gamma_{i1} & \cdots & \gamma_{i(K-1)}
                    \end{array}
                \right]
{{< /katex >}}

となる。γ<sub>ik</sub>は、i番目の入力データがクラスタkに属する確率を示す。

また、これより

{{< katex  >}}
\tag{3}  \sum_{k=0}^{K-1} \gamma_{ik}  =  1
{{< /katex >}}

である。

## データがクラスタに属する確率とは？

そもそもの話だが、入力データがクラスタkに属する確率とはどう言う意味なのか？

具体的な例を使って説明してみよう。先程の例では温度とpHを入力としたデータを利用していた。

ここで、例えば温泉の源泉が複数あり、それらの組み合わさったことによって入力データの温度とpHが実現している、と言う説を考えてみよう。

そうなると、元となる源泉の温度とpHは固定されているので、それらが各クラスタの中心をなしていると考えられ、かつそのようなクラスタが存在しているとも考えることもできる。

このように、観察はできなかったがデータに影響を与えているだろう変量のことを**潜在変数(latent valiable)**または**隠れ変数(hidden variable)**と呼ぶ。


この潜在変数を数式で定義するにはどうすれば良いだろうか。(2)と同様にして、潜在変数の個数をK個とした時、以下のようなz<sub>i</sub>を考えてみる。(0≦i＜N)

{{< katex  >}}
\tag{4}  {\bf z }_{i}  =  
                \left[
                    \begin{array}{cc}
                    z_{i0}  & z_{i1} & \cdots & z_{i(K-1)}
                    \end{array}
                \right]
{{< /katex >}}

式(4)において、z<sub>ij</sub>は、i番目のデータがj番目の潜在変数に属していたら１、属していなければ０をとる変数とする。(0≦j＜K)


