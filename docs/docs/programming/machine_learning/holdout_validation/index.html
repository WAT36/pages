<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ホールドアウト検証 | WAT Notes</title>

<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<link rel="stylesheet" href="https://WAT36.github.io/pages/book.min.e2750c58bf0545d36d2426996f9d6108a275d000f33e7552d83ea28bdcd34ab7.css">


<script defer src="https://WAT36.github.io/pages/search.min.0c30cd756d0217445d4487df0c876dd4506d19d5b7f8e0e9514b825b01355449.js"></script>



<link rel="icon" href="https://WAT36.github.io/pages/favicon.png" type="image/x-icon">


<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" style="display: none" id="menu-control" />
  <main class="flex container">

    <aside class="book-menu fixed">
      <nav>
<h2 class="book-brand">
  <a href="https://WAT36.github.io/pages/">WAT Notes</a>
</h2>


<div class="book-search">
  <input type="text" placeholder="Search" id="book-search-input" maxlength="64" readonly />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>





    
  
  
  

  <style>
  nav ul a[href$="\2f docs\2fprogramming\2fmachine_learning\2fholdout_validation\2f "] {
      color: #004ed0;
  }
  </style>

<ul>
<li><a href="https://WAT36.github.io/pages/"><strong>Introduction</strong></a></li>
</ul>

<p><details>
 <summary>Notes</summary></p>

<ul>
<li>

<ul>
<li><a href="https://WAT36.github.io/pages/docs/programming/jp_index/"><strong>プログラミング</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/ctf/ctf_index/"><strong>CTF</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/container/container_index/"><strong>コンテナ</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/front-end/front_index/"><strong>フロントエンド</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/cloud/aws/aws_index/"><strong>クラウド(AWS)</strong></a></li>
</ul></li>
</ul>

<p></details></p>

<ul>
<li><p><a href="https://WAT36.github.io/pages/posts/"><strong>Blog</strong></a></p></li>

<li><p><a href="https://WAT36.github.io/pages/docs/about/disclaimer/">免責事項</a></p></li>
</ul>








  <div class="page-nav-item">
    <a href="https://WAT36.github.io/pages/categories/">Categories</a>
  </div>
  <br>
  <div class="page-nav-item">
    <a href="https://WAT36.github.io/pages/tags/">Tags</a>
  </div>
</nav>


<script>
(function() {
  var menu = document.querySelector("aside.book-menu nav");
  addEventListener("beforeunload", function(event) {
    localStorage.setItem("menu.scrollTop", menu.scrollTop);
  });
  menu.scrollTop = localStorage.getItem("menu.scrollTop");
})();
</script>

    </aside>

    <div class="book-page">
      <header class="flex align-center justify-between book-header">
  <label for="menu-control">
    <img src="https://WAT36.github.io/pages/svg/menu.svg" alt="Menu" />
  </label>
  <strong>ホールドアウト検証</strong>
</header>

      
<article class="markdown">

<h1 id="ホールドアウト検証">ホールドアウト検証</h1>

<p>先述の<a href="https://WAT36.github.io/pages/docs/programming/machine_learning/overfitting/">オーバーフィッティング(過学習)</a>の章で、Mを大きくすればするほど既存の入力データに対する精度が高くなり、未知の入力に対する予測精度が悪くなるという問題があった。最適なMはどう求めれば良いのだろうか？</p>

<p>その一つの方法として、<strong>ホールドアウト検証</strong>という手法を挙げる。</p>

<p>これは、今ある入力データをいくつかの集合に分割し、そのうちのいくつかを学習に使って予測式を作り、残りのデータでその予測式を使った結果の平均二乗誤差(または標準偏差SD)を算出することでMの評価基準とする、という方法である。</p>

<p>ここで、予測式を作るための学習に使うデータのことを<strong>訓練データ (training data)</strong>といい、作成した予測式の評価に用いるデータを<strong>テストデータ (test data)</strong>と呼ぶ。</p>

<p>では試しに、先述の<a href="https://WAT36.github.io/pages/docs/programming/machine_learning/linear_basis_function/">線形基底関数モデル</a>で利用したデータ(=<a href="https://WAT36.github.io/pages/docs/programming/machine_learning/linear_model/">直線モデル(線形回帰)</a>で利用したデータ)を４分割し、初めの4分の３を訓練データとして学習させ、残りの4分の１をテストデータとして利用し、各Mの評価を行ってみよう。</p>

<p>コードを以下に記載する。(holdout_validation.py)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> math
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> linear_basis_function <span style="color:#f92672">import</span> mse
<span style="color:#f92672">from</span> linear_basis_function <span style="color:#f92672">import</span> design_matrix
<span style="color:#f92672">from</span> linear_basis_function <span style="color:#f92672">import</span> linear_basis_func

<span style="color:#75715e">#入力値</span>
x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;x.npy&#39;</span>)
<span style="color:#75715e">#実測値</span>
t <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;t.npy&#39;</span>)

<span style="color:#75715e">#mを設定</span>
M<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">5</span>,<span style="color:#ae81ff">9</span>,<span style="color:#ae81ff">13</span>]

<span style="color:#75715e">#訓練データ,全体の3/4</span>
n<span style="color:#f92672">=</span>(len(x)<span style="color:#f92672">//</span><span style="color:#ae81ff">4</span>)<span style="color:#f92672">*</span><span style="color:#ae81ff">3</span>
x_train<span style="color:#f92672">=</span>x[:n]
t_train<span style="color:#f92672">=</span>t[:n]

<span style="color:#75715e">#テストデータ</span>
x_test<span style="color:#f92672">=</span>x[n:]
t_test<span style="color:#f92672">=</span>t[n:]

<span style="color:#75715e">#メイン(プロット)</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">20</span>,<span style="color:#ae81ff">7.5</span>))
plt<span style="color:#f92672">.</span>subplots_adjust(wspace<span style="color:#f92672">=</span><span style="color:#ae81ff">0.25</span>,hspace<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(M)):
    plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>,i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)

    m<span style="color:#f92672">=</span>M[i]

    <span style="color:#75715e">#ガウス関数の中心 はxの最小値〜最大値の間で設定</span>
    mu<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>linspace(min(x_train),max(x_train),m)
    <span style="color:#75715e">#訓練データでw,y算出</span>
    w_train <span style="color:#f92672">=</span> design_matrix(x_train,t_train,mu,<span style="color:#ae81ff">1</span>)
    y_test <span style="color:#f92672">=</span> linear_basis_func(w_train,x_test,mu,<span style="color:#ae81ff">1</span>)

    <span style="color:#75715e">#標準偏差SD算出</span>
    sd <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>sqrt(mse(y_test,t_test))

    <span style="color:#75715e">#予測式を細かく表示させるためのデータ作成</span>
    x_forplot <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(min(x_train),max(x_train),<span style="color:#ae81ff">1000</span>)
    y_forplot <span style="color:#f92672">=</span> linear_basis_func(w_train,x_forplot,mu,<span style="color:#ae81ff">1</span>)

    <span style="color:#75715e">#プロット</span>
    plt<span style="color:#f92672">.</span>scatter(x_train,t_train,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;white&#39;</span>,label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>,edgecolors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;black&#34;</span>)
    plt<span style="color:#f92672">.</span>scatter(x_test,t_test,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;green&#39;</span>,label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;test&#39;</span>)
    plt<span style="color:#f92672">.</span>xlim(min(x)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,max(x)<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
    plt<span style="color:#f92672">.</span>ylim(min(t)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,max(t)<span style="color:#f92672">+</span><span style="color:#ae81ff">10</span>)

    plt<span style="color:#f92672">.</span>plot(x_forplot,y_forplot,<span style="color:#e6db74">&#39;-&#39;</span>,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>,label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;y_train&#39;</span>)
    plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;lower right&#39;</span>)
    plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;M={0:d}, SD={1:.2f}&#34;</span><span style="color:#f92672">.</span>format(m,sd))

    plt<span style="color:#f92672">.</span>grid(True)
plt<span style="color:#f92672">.</span>show()</code></pre></div>
<p>実行結果</p>

<p><img src="https://WAT36.github.io/pages/img/datascience/Figure_23.png" width=150%></p>

<p>となり、Mが高くなるほど訓練データへの誤差は少なくなるが、テストデータへの誤差（標準偏差）は大きくなる。</p>

<p>この場合で最適なMを調べるために、各Mにおいて訓練データとテストデータの誤差(標準偏差)を調べてみよう。</p>

<p>各Mにおいて訓練データとテストデータの誤差(標準偏差)を算出し、グラフを作成するコードを以下に記載する。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> math
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> linear_basis_function <span style="color:#f92672">import</span> mse
<span style="color:#f92672">from</span> linear_basis_function <span style="color:#f92672">import</span> design_matrix
<span style="color:#f92672">from</span> linear_basis_function <span style="color:#f92672">import</span> linear_basis_func

<span style="color:#75715e">#入力値</span>
x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;x.npy&#39;</span>)
<span style="color:#75715e">#実測値</span>
t <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;t.npy&#39;</span>)

<span style="color:#75715e">#訓練データ,全体の3/4</span>
n<span style="color:#f92672">=</span>(len(x)<span style="color:#f92672">//</span><span style="color:#ae81ff">4</span>)<span style="color:#f92672">*</span><span style="color:#ae81ff">3</span>
x_train<span style="color:#f92672">=</span>x[:n]
t_train<span style="color:#f92672">=</span>t[:n]

<span style="color:#75715e">#テストデータ</span>
x_test<span style="color:#f92672">=</span>x[n:]
t_test<span style="color:#f92672">=</span>t[n:]

<span style="color:#75715e">#M毎の標準偏差SD</span>
sd_train<span style="color:#f92672">=</span>[]
sd_test<span style="color:#f92672">=</span>[]

<span style="color:#75715e">#メイン(プロット)</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">7.5</span>))

M<span style="color:#f92672">=</span>[i <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">14</span>)]

<span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> M:

    <span style="color:#75715e">#ガウス関数の中心 はxの最小値〜最大値の間で設定</span>
    mu<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>linspace(min(x_train),max(x_train),m)
    <span style="color:#75715e">#訓練データでw,y算出</span>
    w_train <span style="color:#f92672">=</span> design_matrix(x_train,t_train,mu,<span style="color:#ae81ff">1</span>)
    y_test <span style="color:#f92672">=</span> linear_basis_func(w_train,x_test,mu,<span style="color:#ae81ff">1</span>)
    y_train <span style="color:#f92672">=</span> linear_basis_func(w_train,x_train,mu,<span style="color:#ae81ff">1</span>)

    <span style="color:#75715e">#標準偏差SD算出</span>
    sd_train<span style="color:#f92672">.</span>append(math<span style="color:#f92672">.</span>sqrt(mse(y_train,t_train)))
    sd_test<span style="color:#f92672">.</span>append(math<span style="color:#f92672">.</span>sqrt(mse(y_test,t_test)))

<span style="color:#75715e">#プロット</span>
plt<span style="color:#f92672">.</span>xlim(min(M)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,max(M)<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
plt<span style="color:#f92672">.</span>ylim(min(min(sd_train),min(sd_test))<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,max(max(sd_train),max(sd_test))<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)

plt<span style="color:#f92672">.</span>plot(M,sd_train,<span style="color:#e6db74">&#39;-&#39;</span>,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;blue&#39;</span>,label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;SD_train&#39;</span>)
plt<span style="color:#f92672">.</span>plot(M,sd_test,<span style="color:#e6db74">&#39;-&#39;</span>,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>,label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;SD_test&#39;</span>)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;higher left&#39;</span>)

plt<span style="color:#f92672">.</span>grid(True)
plt<span style="color:#f92672">.</span>show()</code></pre></div>
<p>実行結果</p>

<p><img src="https://WAT36.github.io/pages/img/datascience/Figure_24.png" width=50%></p>

<p>のようになり、この図よりテストデータに対して誤差が最も低くなるM=7,10あたりが最も適切なMであると推測できる。</p>

<p>よって、このホールドアウト検証で最適なMが決定できた。</p>

<p>しかし、今回はテストデータが分散しているため良いが、例えばテストデータがひとかたまりになる場合（テストデータを低い順または高い順から取ってくるなど）すると、また学習結果も悪くなるのは予想できると思う。つまり、実はホールドアウト検証はどれを訓練データ及びテストデータに選ぶかによって結果が変わってくるものなのである。</p>

<p>そこで、もう一つの検証方法についてを次章で述べる。</p>
</article>

      
<div class="book-footer justify-between">
  
  <div>
    
    <a href="https://github.com/alex-shpak/hugo-book/commit/66ace37b73db8a197ee46d5bf19b84d3abe39cbd" title='Last modified Apr 29, 2020 by Wataru Tsukagoshi' target="_blank" rel="noopener">
      <img src="https://WAT36.github.io/pages/svg/calendar.svg" alt="Changed" /> Apr 29, 2020
    </a>
  </div>
  
</div>


      
    </div>
    
  



  </main>

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-161908250-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</body>

</html>
