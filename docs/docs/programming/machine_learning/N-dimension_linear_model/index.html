<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>N次元線形回帰モデル | WAT Notes</title>

<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<link rel="stylesheet" href="https://WAT36.github.io/pages/book.min.e2750c58bf0545d36d2426996f9d6108a275d000f33e7552d83ea28bdcd34ab7.css">


<script defer src="https://WAT36.github.io/pages/search.min.ad887627040feee9b3c3d95e1c5f02ffe716745c5daefec368765c5da3da14d8.js"></script>



<link rel="icon" href="https://WAT36.github.io/pages/favicon.png" type="image/x-icon">


<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" style="display: none" id="menu-control" />
  <main class="flex container">

    <aside class="book-menu fixed">
      <nav>
<h2 class="book-brand">
  <a href="https://WAT36.github.io/pages/">WAT Notes</a>
</h2>


<div class="book-search">
  <input type="text" placeholder="Search" id="book-search-input" maxlength="64" readonly />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>





    
  
  
  

  <style>
  nav ul a[href$="\2f docs\2fprogramming\2fmachine_learning\2fN-dimension_linear_model\2f "] {
      color: #004ed0;
  }
  </style>

<ul>
<li><a href="https://WAT36.github.io/pages/"><strong>Introduction</strong></a></li>
</ul>

<p><details>
 <summary>Notes</summary></p>

<ul>
<li>

<ul>
<li><a href="https://WAT36.github.io/pages/docs/programming/jp_index/"><strong>プログラミング</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/ctf/ctf_index/"><strong>CTF</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/front-end/front_index/"><strong>フロントエンド</strong></a></li>
<li><a href="https://WAT36.github.io/pages/docs/cloud/aws/aws_index/"><strong>クラウド(AWS)</strong></a></li>
</ul></li>
</ul>

<p></details></p>

<ul>
<li><p><a href="https://WAT36.github.io/pages/posts/"><strong>Blog</strong></a></p></li>

<li><p><a href="https://WAT36.github.io/pages/docs/about/disclaimer/">免責事項</a></p></li>
</ul>








  <div class="page-nav-item">
    <a href="https://WAT36.github.io/pages/categories/">Categories</a>
  </div>
  <br>
  <div class="page-nav-item">
    <a href="https://WAT36.github.io/pages/tags/">Tags</a>
  </div>
</nav>


<script>
(function() {
  var menu = document.querySelector("aside.book-menu nav");
  addEventListener("beforeunload", function(event) {
    localStorage.setItem("menu.scrollTop", menu.scrollTop);
  });
  menu.scrollTop = localStorage.getItem("menu.scrollTop");
})();
</script>

    </aside>

    <div class="book-page">
      <header class="flex align-center justify-between book-header">
  <label for="menu-control">
    <img src="https://WAT36.github.io/pages/svg/menu.svg" alt="Menu" />
  </label>
  <strong>N次元線形回帰モデル</strong>
</header>

      
<article class="markdown">

<h1 id="n次元線形回帰モデル">N次元線形回帰モデル</h1>

<p>先程までの章では1次元(直線モデル)、2次元(面モデル)の入力データを扱ってきたが、そこから更に次元を広げたN次元の入力データの場合はどうなるだろうか。
ここではそれについてを述べる。</p>

<p>N次元での入力データから予測値yを算出する式は以下の式で表される。</p>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css" integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js" integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



<p class="katex">
  $$ 
\tag{1}  y=w_{0} x_{0} + w_{1} x_{1} + w_{2} x_{2} + \cdots + w_{N-1} x_{N-1} + w_{N} (w_{i} は実数)
 $$
</p>



<p>N次元の時も1次元2次元の時と同様に式(1)の様な形で表される。この式の形で表されるモデルは<strong>線形回帰モデル</strong>と呼ばれている。</p>

<p>式(1)において、最後のw<sub>N</sub>には入力データがない事に注意する。 (切片である)</p>

<p>ここでは簡略化のため、以降w<sub>N</sub> = 0として考える。すると式(1)は以下の様になる。</p>



<p class="katex">
  $$ 
\tag{2}  y=w_{0} x_{0} + w_{1} x_{1} + w_{2} x_{2} + \cdots + w_{N-1} x_{N-1} 
 $$
</p>



<p>この式(2)を行列表記で書き直すと、以下の様になる。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{3}  y  &= w_{0} x_{0} + w_{1} x_{1} + w_{2} x_{2} + \cdots + w_{N-1} x_{N-1} \\
            &=  \left[
                    \begin{array}{ccc}
                    w_{0} & \cdots & w_{N-1} 
                    \end{array}
                \right]
                \left[
                    \begin{array}{cccc}
                    x_{0} \\
                    \vdots \\
                    x_{N-1}
                    \end{array}
                \right]
            \\
            &= {\bf w} ^\mathrm{T} {\bf x} 
\end{aligned}
 $$
</p>



<p>ここで</p>



<p class="katex">
  $$ 
  {\bf w} = \left[
    \begin{array}{cccc}
      w_{0} \\
      w_{1} \\
      \vdots \\
      w_{N-1}
    \end{array}
  \right]
  ,
    {\bf x} = \left[
    \begin{array}{cccc}
      x_{0} \\
      x_{1} \\
      \vdots \\
      x_{N-1}
    \end{array}
  \right]
 $$
</p>



<p>とおく。</p>

<hr>

<p>では、ここからN次元線形回帰モデルの解析解を求めてみよう。</p>

<p>これまでと同様にして、平均二乗誤差Jは以下の様に表される。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{4}  J( {\bf w} ) &= \frac{1}{N} \sum_{n=0}^{N-1} ( y(x_{n}) - t_{n} )^2 \\
                      &= \frac{1}{N} \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} )^2
\end{aligned}
 $$
</p>



<p>ここも同様にして、式(4)をw<sub>i</sub>で偏微分すると、以下の様になる。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{5}  \frac{\partial J}{\partial w_{i} } 
            &= \frac{1}{N} \sum_{n=0}^{N-1} \frac{\partial }{\partial w_{i} } ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} )^2 \\
            &= \frac{2}{N} \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) x_{n,i} 
\end{aligned}
 $$
</p>



<p>なお、x<sub>n,i</sub>はn番目の入力データにおけるi番目のパラメータである。</p>

<p>また、<b>w</b><sup>T</sup><b>x</b>をw<sub>i</sub>で偏微分すると、x<sub>n,i</sub>だけが残る事に注意する。</p>

<p>Jを最小にする<b>w</b>では、全てのw<sub>i</sub>について傾き0、つまり式(5)が０になるので、次の式が全てのiで成り立つ。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{6}  \frac{2}{N} \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) x_{n,i} &= 0 \\
\Leftrightarrow  \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) x_{n,i} &= 0
\end{aligned}
 $$
</p>



<p>式(6)は全てのi (0≦i≦N-1) で成り立つ。つまり以下の式が成り立つ。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{7} \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) x_{n,0} &= 0 \\
        \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) x_{n,1} &= 0 \\
        \vdots \\
        \sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) x_{n,N-1} &= 0 
\end{aligned}
 $$
</p>



<p>この式をベクトルを使って書き換えると以下の式の様になる。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{8} &\sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) [ x_{n,0}, x_{n,1}, \cdots , x_{n,N-1} ] 
        = 
                \left[
                    \begin{array}{ccc}
                    0 & 0 & \cdots & 0 
                    \end{array}
                \right]  \\
        \Leftrightarrow 
        &\sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} - t_{n} ) {\bf x}_{n} ^\mathrm{T}
        = 
                \left[
                    \begin{array}{ccc}
                    0 & 0 & \cdots & 0 
                    \end{array}
                \right] \\
        \Leftrightarrow 
        &\sum_{n=0}^{N-1} ( {\bf w} ^\mathrm{T} {\bf x}_{n} {\bf x}_{n} ^\mathrm{T} 
                          - t_{n} {\bf x}_{n} ^\mathrm{T} ) 
        = 
                \left[
                    \begin{array}{ccc}
                    0 & 0 & \cdots & 0 
                    \end{array}
                \right] \\
        \Leftrightarrow 
        & {\bf w} ^\mathrm{T} \sum_{n=0}^{N-1} {\bf x}_{n} {\bf x}_{n} ^\mathrm{T} 
          -  \sum_{n=0}^{N-1} t_{n} {\bf x}_{n} ^\mathrm{T}  
        = 
                \left[
                    \begin{array}{ccc}
                    0 & 0 & \cdots & 0 
                    \end{array}
                \right]
\end{aligned}
 $$
</p>



<p>ここで</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{9} 
         \sum_{n=0}^{N-1} {\bf x}_{n} {\bf x}_{n} ^\mathrm{T} 
        &= 
         \sum_{n=0}^{N-1}
                \left[
                    \begin{array}{cccc}
                    x_{n,0} \\
                    x_{n,1} \\
                    \vdots \\
                    x_{n,N-1}
                    \end{array}
                \right]
                \left[
                    \begin{array}{ccc}
                    x_{n,0} & x_{n,1} & \cdots & x_{n,N-1} 
                    \end{array}
                \right] \\
        &= 
          \sum_{n=0}^{N-1}
                \left[
                    \begin{array}{cccc}
                    x_{n,0}^2 & x_{n,0} x_{n,1} & \cdots & x_{n,0} x_{n,N-1} \\
                    x_{n,1} x_{n,0} & x_{n,1}^2 & \cdots & x_{n,1} x_{n,N-1} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    x_{n,N-1} x_{n,0} & x_{n,N-1} x_{n,1} & \cdots & x_{n,N-1}^2
                    \end{array}
                \right] \\
        &=
                \left[
                    \begin{array}{llll}
                    \displaystyle \sum_{n=0}^{N-1} x_{n,0}^2 & \displaystyle \sum_{n=0}^{N-1} x_{n,0} x_{n,1} & \cdots & \displaystyle \sum_{n=0}^{N-1} x_{n,0} x_{n,N-1} \\
                    \displaystyle \sum_{n=0}^{N-1} x_{n,1} x_{n,0} & \displaystyle \sum_{n=0}^{N-1} x_{n,1}^2 & \cdots & \displaystyle \sum_{n=0}^{N-1} x_{n,1} x_{n,N-1} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    \displaystyle \sum_{n=0}^{N-1} x_{n,N-1} x_{n,0} & \displaystyle \sum_{n=0}^{N-1} x_{n,N-1} x_{n,1} & \cdots & \displaystyle \sum_{n=0}^{N-1} x_{n,N-1}^2
                    \end{array}
                \right] \\
        &=
                \left[
                    \begin{array}{llll}
                    x_{0,0} & x_{1,0} & \cdots & x_{N-1,0} \\
                    x_{0,1} & x_{1,1} & \cdots & x_{N-1,1} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    x_{0,N-1} & x_{1,N-1} & \cdots & x_{N-1,N-1}
                    \end{array}
                \right] 
                \left[
                    \begin{array}{llll}
                    x_{0,0} & x_{0,1} & \cdots & x_{0,N-1} \\
                    x_{1,0} & x_{1,1} & \cdots & x_{1,N-1} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    x_{N-1,0} & x_{N-1,1} & \cdots & x_{N-1,N-1}
                    \end{array}
                \right] \\
        &= {\bf X} ^\mathrm{T} {\bf X}


\end{aligned}
 $$
</p>





<p class="katex">
  $$ 
\begin{aligned}
\tag{10} 
         \sum_{n=0}^{N-1} t_{n} {\bf x}_{n} ^\mathrm{T} 
        &= 
         \sum_{n=0}^{N-1}
                t_{n}
                \left[
                    \begin{array}{ccc}
                    x_{n,0} & x_{n,1} & \cdots & x_{n,N-1} 
                    \end{array}
                \right] \\
        &= 
          \sum_{n=0}^{N-1}
                \left[
                    \begin{array}{ccc}
                    t_{n} x_{n,0} & t_{n} x_{n,1} & \cdots & t_{n} x_{n,N-1} 
                    \end{array}
                \right] \\
        &=
                \left[
                    \begin{array}{llll}
                    \displaystyle \sum_{n=0}^{N-1} t_{n} x_{n,0} & \displaystyle \sum_{n=0}^{N-1} t_{n} x_{n,1} & \cdots & \displaystyle \sum_{n=0}^{N-1} t_{n} x_{n,N-1} 
                    \end{array}
                \right] \\
        &=
                \left[
                    \begin{array}{ccc}
                    t_{0} & t_{1} & \cdots & t_{N-1} 
                    \end{array}
                \right]
                \left[
                    \begin{array}{llll}
                    x_{0,0} & x_{0,1} & \cdots & x_{0,N-1} \\
                    x_{1,0} & x_{1,1} & \cdots & x_{1,N-1} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    x_{N-1,0} & x_{N-1,1} & \cdots & x_{N-1,N-1}
                    \end{array}
                \right] \\
        &= {\bf t} ^\mathrm{T} {\bf X}
\end{aligned}
 $$
</p>



<p>とおく、ここで</p>



<p class="katex">
  $$ 
\tag{11} 
        {\bf t}
        = 
                \left[
                    \begin{array}{cccc}
                    t_{0} \\
                    t_{1} \\
                    \vdots \\
                    t_{N-1}
                    \end{array}
                \right]
        ,
        {\bf X}
        = 
                \left[
                    \begin{array}{cccc}
                    x_{0,0} & x_{0,1} & \cdots & x_{0,N-1} \\
                    x_{1,0} & x_{1,1} & \cdots & x_{1,N-1} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    x_{N-1,0} & x_{N-1,1} & \cdots & x_{N-1,N-1}
                    \end{array}
                \right]
 $$
</p>



<p>である。</p>

<p>これより、式(8)は以下式(12)の様に書き換えられる。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{12}  & {\bf w} ^\mathrm{T} \sum_{n=0}^{N-1} {\bf x}_{n} {\bf x}_{n} ^\mathrm{T} 
          -  \sum_{n=0}^{N-1} t_{n} {\bf x}_{n} ^\mathrm{T}  
        &= 
                \left[
                    \begin{array}{ccc}
                    0 & 0 & \cdots & 0 
                    \end{array}
                \right] \\
        \Leftrightarrow 
        & {\bf w} ^\mathrm{T} {\bf X} ^\mathrm{T} {\bf X} -  {\bf t} ^\mathrm{T} {\bf X}
        &= 
                \left[
                    \begin{array}{ccc}
                    0 & 0 & \cdots & 0 
                    \end{array}
                \right] 
\end{aligned}
 $$
</p>



<p>式(12)で<b>t</b><sup>T</sup><b>X</b>を右辺に移項すると</p>



<p class="katex">
  $$ 
\tag{13}  {\bf w} ^\mathrm{T}  {\bf X} ^\mathrm{T} {\bf X} 
        = {\bf t} ^\mathrm{T}  {\bf X} 
 $$
</p>



<p>ここで両辺を転置すると、(<b>AB</b>)<sup>T</sup> = <b>B</b><sup>T</sup><b>A</b><sup>T</sup>より式(13)は</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{14}   ( {\bf w} ^\mathrm{T}  {\bf X} ^\mathrm{T} {\bf X} )^\mathrm{T}
        &= ( {\bf t} ^\mathrm{T}  {\bf X} )^\mathrm{T} \\
           ( {\bf X} ^\mathrm{T} {\bf X} )^\mathrm{T} ({\bf w} ^\mathrm{T}) ^\mathrm{T}
        &= {\bf X} ^\mathrm{T}  {\bf t} \\
           ( {\bf X} ^\mathrm{T} {\bf X} ) {\bf w}
        &= {\bf X} ^\mathrm{T}  {\bf t}
\end{aligned}
 $$
</p>



<p>となり、この式(14)に左から(<b>X</b><sup>T</sup><b>X</b>)<sup>-1</sup>をかける事により、<b>w</b>は以下の式(15)の様に表される。</p>



<p class="katex">
  $$ 
\tag{15}   {\bf w} = ( {\bf X} ^\mathrm{T}  {\bf X} )^{-1} {\bf X} ^\mathrm{T} {\bf t}
 $$
</p>



<p>よって、長くなったが式(15)により<b>w</b>の値が導出された。またこれがN次元線形回帰モデルの解となる。</p>

<p>そして、式(15)の右辺の式 (<b>X</b><sup>T</sup><b>X</b>)<sup>-1</sup><b>X</b><sup>T</sup>
は<strong>ムーアーペンローズの擬似逆行列</strong>という名が付けられている。</p>

<hr>

<p>さて、式(2)で計算の簡略化のためw<sub>N</sub>=0としたと書いたが、w<sub>N</sub>≠0の場合も勿論ある。その場合<b>w</b>や<b>x</b>の次数が異なるがどうすれば良いのか？</p>

<p>その場合、w<sub>N</sub>にもダミー用のパラメータであるx<sub>N</sub>を追加する。</p>

<p>ここで、常にx<sub>N</sub>=1 となる様に設定する。</p>



<p class="katex">
  $$ 
\begin{aligned}
\tag{16}     y &= w_{0} x_{0} + w_{1} x_{1} + w_{2} x_{2} + \cdots + w_{N-1} x_{N-1} + w_{N} \\
           \Leftrightarrow  y &= w_{0} x_{0} + w_{1} x_{1} + w_{2} x_{2} + \cdots + w_{N-1} x_{N-1} + w_{N} x_{N} ( x_{N} = 1)
\end{aligned}
 $$
</p>



<p>この式(16)に対しムーアーペンローズの擬似逆行列を作成すれば、wが求められる。これによりw<sub>N</sub>≠0の場合においても解が求められた。</p>
</article>

      
<div class="book-footer justify-between">
  
  <div>
    
    <a href="https://github.com/alex-shpak/hugo-book/commit/633321a4ff8631bd0021802e57d0e4a75ac40bc0" title='Last modified Apr 25, 2020 by Wataru Tsukagoshi' target="_blank" rel="noopener">
      <img src="https://WAT36.github.io/pages/svg/calendar.svg" alt="Changed" /> Apr 25, 2020
    </a>
  </div>
  
</div>


      
    </div>
    
  



  </main>

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-161908250-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</body>

</html>
